{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3d5e1-1f8d-4fea-a859-9998072aff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Handwritten Character Detection using PyTorch, Keras and Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c382bdbc-076f-4a3b-91c8-a6c2be38aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:02<00:00, 3529181.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 140301.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01<00:00, 1257161.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 2363882.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "[1,   100] loss: 0.627\n",
      "[1,   200] loss: 0.323\n",
      "[1,   300] loss: 0.263\n",
      "[1,   400] loss: 0.250\n",
      "[1,   500] loss: 0.212\n",
      "[1,   600] loss: 0.187\n",
      "[1,   700] loss: 0.177\n",
      "[1,   800] loss: 0.162\n",
      "[1,   900] loss: 0.163\n",
      "[2,   100] loss: 0.130\n",
      "[2,   200] loss: 0.121\n",
      "[2,   300] loss: 0.120\n",
      "[2,   400] loss: 0.111\n",
      "[2,   500] loss: 0.117\n",
      "[2,   600] loss: 0.108\n",
      "[2,   700] loss: 0.107\n",
      "[2,   800] loss: 0.106\n",
      "[2,   900] loss: 0.101\n",
      "[3,   100] loss: 0.075\n",
      "[3,   200] loss: 0.083\n",
      "[3,   300] loss: 0.084\n",
      "[3,   400] loss: 0.091\n",
      "[3,   500] loss: 0.088\n",
      "[3,   600] loss: 0.073\n",
      "[3,   700] loss: 0.075\n",
      "[3,   800] loss: 0.067\n",
      "[3,   900] loss: 0.075\n",
      "[4,   100] loss: 0.059\n",
      "[4,   200] loss: 0.063\n",
      "[4,   300] loss: 0.061\n",
      "[4,   400] loss: 0.061\n",
      "[4,   500] loss: 0.057\n",
      "[4,   600] loss: 0.062\n",
      "[4,   700] loss: 0.057\n",
      "[4,   800] loss: 0.049\n",
      "[4,   900] loss: 0.068\n",
      "[5,   100] loss: 0.049\n",
      "[5,   200] loss: 0.051\n",
      "[5,   300] loss: 0.046\n",
      "[5,   400] loss: 0.053\n",
      "[5,   500] loss: 0.044\n",
      "[5,   600] loss: 0.050\n",
      "[5,   700] loss: 0.040\n",
      "[5,   800] loss: 0.035\n",
      "[5,   900] loss: 0.048\n",
      "Finished Training\n",
      "PyTorch - Accuracy of the network on the 10000 test images: 97 %\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhagy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.5809 - val_accuracy: 0.9527 - val_loss: 0.1727\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1579 - val_accuracy: 0.9636 - val_loss: 0.1291\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.1075 - val_accuracy: 0.9669 - val_loss: 0.1096\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0796 - val_accuracy: 0.9683 - val_loss: 0.1033\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0639 - val_accuracy: 0.9709 - val_loss: 0.0991\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.1031\n",
      "\n",
      "Keras - Test Loss: 0.08847540616989136\n",
      "Keras - Test Accuracy: 0.9728000164031982\n",
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.5764 - val_accuracy: 0.9532 - val_loss: 0.1723\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.1635 - val_accuracy: 0.9618 - val_loss: 0.1291\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.1071 - val_accuracy: 0.9678 - val_loss: 0.1103\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0826 - val_accuracy: 0.9713 - val_loss: 0.0948\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0590 - val_accuracy: 0.9734 - val_loss: 0.0892\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0902\n",
      "\n",
      "TensorFlow - Test Loss: 0.08084995299577713\n",
      "TensorFlow - Test Accuracy: 0.9767000079154968\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch Implementation\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model_pytorch = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_pytorch.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_pytorch(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model_pytorch(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('PyTorch - Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# Keras Implementation\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28, 28).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28).astype('float32') / 255.0\n",
    "\n",
    "# Define the simple model\n",
    "model_keras = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_keras.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_keras.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_keras, test_accuracy_keras = model_keras.evaluate(X_test, y_test)\n",
    "print(\"\\nKeras - Test Loss:\", test_loss_keras)\n",
    "print(\"Keras - Test Accuracy:\", test_accuracy_keras)\n",
    "\n",
    "# TensorFlow Implementation\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28, 28).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28).astype('float32') / 255.0\n",
    "\n",
    "# Define the simple model\n",
    "model_tf = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_tf.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_tf.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_tf, test_accuracy_tf = model_tf.evaluate(X_test, y_test)\n",
    "print(\"\\nTensorFlow - Test Loss:\", test_loss_tf)\n",
    "print(\"TensorFlow - Test Accuracy:\", test_accuracy_tf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
